{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "This notebook shows how to make synthetic data to bootstrap evaluation of your retrieval system. \n",
    "\n",
    "This synthetic data contains many triplets of `(RAG system input, system output, desired chunk to retrieve)`. For this example, we will work on a hardware retailer's system to answer user questions based on existing product previous. So the synthetic data will look like\n",
    "\n",
    "```\n",
    "Q: How frequently do I need to replace the blades on this saw?\n",
    "A: A customer reported getting 7-10 hours of active use between blade replacements.\n",
    "Chunk ID: 3\n",
    "```\n",
    "\n",
    "Once you have many of these triplets, you can experiments with different retrieval strategies (e.g. different embedding models, embedding vs keyword search, etc) to determine which strategies most consistently retrieve the desired chunks.\n",
    "\n",
    "# A Starting Point\n",
    "\n",
    "A simple approach would follow pseudo code:\n",
    "\n",
    "```\n",
    "synth_data = []\n",
    "for chunk in corpus:\n",
    "    response = call_llm(f\"Give me a JSON array of 10 question/answer pairs. The questions should be things someone might ask about a product before purchase. The answer should be something contained in this text: {chunk}\")\n",
    "    q_a = json.loads(response.content)\n",
    "    q_a_c = [{'question': q, 'answer': a, 'chunk': chunk} for (q, a) in q_a_pairs]\n",
    "    synth_data.extend(q_a_c)\n",
    "```\n",
    "\n",
    "A practical implementation should address three issues that arise in the naive pseudo code.\n",
    "\n",
    "| Issue | Solution |\n",
    "|---------|----------|\n",
    "| Inconsistent formatting of LLM response (e.g. different keys) | Instructor library |\n",
    "| Bad questions | Guidance/examples in prompt |\n",
    "| Time waiting for LLM responses when iterating over many chunks | Async LLM calls|\n",
    "\n",
    "# Reusable Code to Bootstrap Evals\n",
    "\n",
    "The code in this notebook addresses these issues. The code is also available as [this script](https://gist.github.com/jxnl/5627c9d463ffe0b085896f7890fab1bf).\n",
    "\n",
    "## Data\n",
    "\n",
    "This course uses synthetic data based on the use-case of answering questions on a hardware retailer's website based on product reviews. We have created this data in `make_product_reviews.ipynb`. Here is a small sample of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       I've been using this cordless drill for over a year now on various home improvement projects and it hasn't let me down once. The adjustable speed settings m...\n",
       "1       This cordless drill is a gem! It's extremely lightweight, which is a big plus when working on overhead projects. The ergonomic grip is comfortable, even dur...\n",
       "2       I bought this drill for my DIY projects around the house, and it was one of the best investments. It's got a nice weight balance that's neither too heavy no...\n",
       "3       As a professional contractor, I rely on durable and efficient tools. This cordless drill exceeds my expectations. It's powerful enough to drive screws into ...\n",
       "4       This cordless drill packs a punch for its size. I've used it for everything from installing shelves to building a deck. The torque settings are easy to adju...\n",
       "                                                                                     ...                                                                               \n",
       "1253    During wildfire season, this dust mask proved invaluable. The breathable fabric made it easy to wear, and it offered great protection against ash and partic...\n",
       "1254    My job as a carpenter exposes me to a lot of sawdust, and these masks have made my work environment much safer. The flexible nose piece is great for customi...\n",
       "1255    This dust mask was very useful for my recent DIY home project. It has a snug fit that prevents dust and debris from entering, and the breathable design kept...\n",
       "1256    Working in construction means dealing with a lot of dust. These masks have been reliable and comfortable. The air flows through easily, so I don’t feel suff...\n",
       "1257    Cleaning out my attic was a much easier task with these dust masks. They block out dust effectively, and the breathable fabric ensures you don’t get too war...\n",
       "Name: review, Length: 1258, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lancedb\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)\n",
    "\n",
    "db = lancedb.connect(\"./lancedb\")\n",
    "reviews_table = db.open_table(\"reviews\")\n",
    "sample_reviews = reviews_table.to_pandas()\n",
    "sample_reviews.review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure The Data\n",
    "\n",
    "We use Pydantic & Instructor for a reliable interface between our LLMs and the structured data formats we need to run code on LLM output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    id: str\n",
    "    product_title: str\n",
    "    product_description: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "sample_chunks = [\n",
    "    Review(\n",
    "        id=str(row.id),\n",
    "        product_title=row.product_title,\n",
    "        product_description=row.product_description,\n",
    "        review=row.review,\n",
    "    )\n",
    "    for _, row in sample_reviews.iterrows()\n",
    "]\n",
    "\n",
    "n_questions = 2  # number of questions to get in each LLM call\n",
    "example_questions = [\n",
    "    \"What does the reviewer like about the product?\",\n",
    "    \"What does the reviewer think could be improved?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see how we build questions on a single chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How long does the battery last on this cordless drill?', answer='The battery lasts a good 4-5 hours of continuous use before needing a recharge.', chunk_id='0'),\n",
       " ChunkEval(question='Can this cordless drill handle tough materials?', answer='Yes, it can drill into tough materials like concrete.', chunk_id='0')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "import instructor\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "# Patch the AsyncOpenAI client\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class QuestionAnswer(BaseModel):\n",
    "    question: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "class ChunkEval(QuestionAnswer):\n",
    "    chunk_id: str\n",
    "\n",
    "\n",
    "async def generate_evals(\n",
    "    review: Review, n_questions: int, example_questions: List[str]\n",
    ") -> List[ChunkEval]:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Generate `{n_questions}` question-answer pairs about a {review.product_title}. The answers should primarily be derived from information in this product review:\n",
    "\n",
    "        <content>\n",
    "        {review.review}\n",
    "        </content>\n",
    "\n",
    "        While they should contain information from the product review, you may also find it helpful context to see a product description:\n",
    "        <content>\n",
    "        {review.product_description}\n",
    "        </content>\n",
    "\n",
    "        Example questions:\n",
    "        {chr(10).join(f'- {q}' for q in example_questions)}\n",
    "\n",
    "        Provide a concise and specific answer for each question.\n",
    "        Do not use the exact example questions. Use them only as inspiration for the types of more specific questions to generate.\n",
    "        Do not include answers that are not in the content.\n",
    "        Questions should ask about product characteristics (e.g. durability) and answers should refer to product characteristics without referring to the reviewer specifically.\n",
    "        Stylistically, the questions should resemble what people would ask a RAG-based answer bot on a retailer's website. So they can be a little informal, messy or scattered.\n",
    "        \"\"\"\n",
    "\n",
    "    try:\n",
    "        pairs = client.chat.completions.create_iterable(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=QuestionAnswer,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return [\n",
    "            ChunkEval(question=pair.question, answer=pair.answer, chunk_id=review.id)\n",
    "            async for pair in pairs\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "first_chunk_res = await generate_evals(sample_chunks[0], n_questions, example_questions)\n",
    "first_chunk_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `generate_evals` for many chunks in parallel, wrap it with a function that also takes a semaphore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChunkEval(question='How long does the battery last on this cordless drill?', answer='The battery lasts a good 4-5 hours of continuous use before needing a recharge.', chunk_id='0'),\n",
       " ChunkEval(question='Is this cordless drill versatile for different tasks?', answer='Yes, it has adjustable speed settings that make it versatile enough to handle everything from delicate tasks like assembling furniture to drilling into tough materials like concrete.', chunk_id='0')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "\n",
    "class ChunkProcessingError(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "async def process_chunk(\n",
    "    review: Review,\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    semaphore: asyncio.Semaphore,\n",
    ") -> List[ChunkEval]:\n",
    "    async with semaphore:\n",
    "        try:\n",
    "            return await generate_evals(review, n_questions, example_questions)\n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error processing chunk {review.id}: {str(e)}\")\n",
    "            raise ChunkProcessingError(f\"Failed to process chunk {review.id}\") from e\n",
    "\n",
    "\n",
    "# Test that we get the same results as directly calling generate_evals\n",
    "await process_chunk(\n",
    "    sample_chunks[0], n_questions, example_questions, asyncio.Semaphore(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can call `process_chunks` with all chunks to build the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2518 ChunkEvals.\n",
      "Dataset saved as 'synthetic_eval_dataset.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "async def create_synthetic_dataset(\n",
    "    reviews: List[Review],\n",
    "    n_questions: int,\n",
    "    example_questions: List[str],\n",
    "    max_concurrency: int = 10,\n",
    ") -> List[ChunkEval]:\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [\n",
    "        process_chunk(review, n_questions, example_questions, semaphore)\n",
    "        for review in reviews\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "    dataset = []\n",
    "    for result in results:\n",
    "        if isinstance(result, ChunkProcessingError):\n",
    "            print(result)\n",
    "        elif isinstance(result, list):\n",
    "            dataset.extend(result)\n",
    "        else:\n",
    "            print(f\"Unexpected result type: {type(result)}\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def save_dataset(dataset: List[ChunkEval], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump([chunk_eval.model_dump() for chunk_eval in dataset], f, indent=2)\n",
    "\n",
    "\n",
    "synthetic_dataset = await create_synthetic_dataset(\n",
    "    sample_chunks, n_questions, example_questions\n",
    ")\n",
    "save_dataset(synthetic_dataset, \"synthetic_eval_dataset.json\")\n",
    "\n",
    "print(f\"Generated {len(synthetic_dataset)} ChunkEvals.\")\n",
    "print(\"Dataset saved as 'synthetic_eval_dataset.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the data as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How long does the battery last on this cordless drill before needing a recharge?</td>\n",
       "      <td>The battery lasts a good 4-5 hours of continuous use before needing a recharge.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can this cordless drill handle tough materials?</td>\n",
       "      <td>Yes, it is versatile enough to handle tough materials like concrete.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Is this cordless drill easy to handle for overhead work?</td>\n",
       "      <td>Yes, it's extremely lightweight, which is a big plus when working on overhead projects.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What features come with this drill?</td>\n",
       "      <td>The set includes two batteries, a charger, and a handy carrying case.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How's the weight balance on this cordless drill?</td>\n",
       "      <td>The cordless drill has a nice weight balance that's neither too heavy nor too light.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           question  \\\n",
       "0  How long does the battery last on this cordless drill before needing a recharge?   \n",
       "1                                   Can this cordless drill handle tough materials?   \n",
       "2                          Is this cordless drill easy to handle for overhead work?   \n",
       "3                                               What features come with this drill?   \n",
       "4                                  How's the weight balance on this cordless drill?   \n",
       "\n",
       "                                                                                    answer  \\\n",
       "0          The battery lasts a good 4-5 hours of continuous use before needing a recharge.   \n",
       "1                     Yes, it is versatile enough to handle tough materials like concrete.   \n",
       "2  Yes, it's extremely lightweight, which is a big plus when working on overhead projects.   \n",
       "3                    The set includes two batteries, a charger, and a handy carrying case.   \n",
       "4     The cordless drill has a nice weight balance that's neither too heavy nor too light.   \n",
       "\n",
       "  chunk_id  \n",
       "0        0  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(i.question, i.answer, i.chunk_id) for i in synthetic_dataset]\n",
    "pd.DataFrame(data, columns=[\"question\", \"answer\", \"chunk_id\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sys-imp-rag",
   "language": "python",
   "name": "sys-imp-rag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
